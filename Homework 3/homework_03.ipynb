{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "latex_envs": {
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 0
    },
    "colab": {
      "name": "homework_03.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhgNFSteVXL7"
      },
      "source": [
        "# Homework 3\n",
        "\n",
        "\n",
        "## References\n",
        "\n",
        "+ Lectures 7-10 (inclusive).\n",
        "\n",
        "## Instructions\n",
        "\n",
        "+ Type your name and email in the \"Student details\" section below.\n",
        "+ Develop the code and generate the figures you need to solve the problems using this notebook.\n",
        "+ For the answers that require a mathematical proof or derivation you can either:\n",
        "    \n",
        "    - Type the answer using the built-in latex capabilities. In this case, simply export the notebook as a pdf and upload it on gradescope; or\n",
        "    - You can print the notebook (after you are done with all the code), write your answers by hand, scan, turn your response to a single pdf, and upload on gradescope.\n",
        "\n",
        "**Note**: \n",
        "+ Please match all the pages corresponding to each of the questions when you submit on gradescope. \n",
        "\n",
        "**Important:**\n",
        "If you are running the notebook on Google Colab make sure you make a copy on your Google Drive so that you can resume your work later. To do this click on \"File->Save a copy in Drive.\" Rename the copy as you wish by clicking on the filename you see on the very top. Then make sure you save regularly. If you close your browser, you can resume your work by going to your Google Drive and clicking on the notebook. You can find the notebooks the folder \"My Drive/Colab Notebooks.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTYRfXvKVXL9"
      },
      "source": [
        "## Student details\n",
        "\n",
        "+ **First Name:** Yihong\n",
        "+ **Last Name:** Ji \n",
        "+ **Email:** yihong_ji@mymail.sutd.edu.sg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hn_MT2vsVXL-"
      },
      "source": [
        "# Here are some modules that you may need - please run this block of code:\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "sns.set_context('talk')\n",
        "import numpy as np\n",
        "import scipy\n",
        "import scipy.stats as st"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gJVIruAVXL-"
      },
      "source": [
        "## Problem 0\n",
        "\n",
        "This is not a real problem. You just have to follow the instruction to make sure that you have access to the required data files for completing the subsequent problems.\n",
        "There are two data files needed for this purpose:\n",
        "\n",
        "+ [hw_03_p1B_data.txt](https://raw.githubusercontent.com/PredictiveScienceLab/data-analytics-se/master/homework/hw_03_p1B_data.txt) which is needed for Problem 1/Part B.\n",
        "\n",
        "+ [hw_03_p2_data.txt](https://raw.githubusercontent.com/PredictiveScienceLab/data-analytics-se/master/homework/hw_03_p2_data.txt) which is needed for Problem 2.\n",
        "\n",
        "Our goal is to make sure that this Jupyter notebook can see these two files.\n",
        "There are three cases that we are going to consider.\n",
        "The cases depend on how you accessed the notebook and where you are currently running it.\n",
        "You only need to choose and carry out the instructions for the case that is relevant to you:\n",
        "\n",
        "### Instructions for Google Colab\n",
        "Google Colab gives you a computational session with temporary storage.\n",
        "The data must be visible from there.\n",
        "The best way to do this is to put the data in your Google drive and access the drive from this session.\n",
        "Here is how:\n",
        "+ First, right click on the two files above and then \"Save As.\" Make sure that the selected format is \"text.\" Remember where you save the files in your local computer.\n",
        "+ Second, go to your Google Drive. We need to select a folder to put the files. To keep things simple, let's just dump everything in \"My Drive/Colab Notebooks,\" i.e., the same folder that contains the copy of this Jupyter notebook which you should have already made (if not, please see the **important** section at the very top. Once you have entered this folder in your Google Drive (just double click on it), drag and drop the two files in there. This is how your Google Drive should look like:\n",
        "\n",
        "![Google Drive screenshot](https://github.com/PredictiveScienceLab/data-analytics-se/blob/master/homework/hw_03_google_drive_screenshot.png?raw=1)\n",
        "\n",
        "+ Now we need to make the Google Drive visible from this computational session.\n",
        "We do this by *mounting* the drive.\n",
        "You need to run this code and follow the instructions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFbptqeqVXL_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c36af9b4-1d9d-40ac-8143-99af6de2b441"
      },
      "source": [
        "# The following code does not run unless you are running the notebook on Google Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaAMSN5gVXL_"
      },
      "source": [
        "+ Finally, change directories so that the data files are in the current working directory:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKLlotwBVXL_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54203a5e-bb75-470b-9d0b-f3ff96d5806d"
      },
      "source": [
        "# Only if you are running on Google Colab...\n",
        "# Print working directory before changing\n",
        "!pwd\n",
        "# Change to the desired directory on Google drive\n",
        "%cd \"/content/drive/My Drive/Colab Notebooks\"\n",
        "# Print working directory after changing\n",
        "!pwd\n",
        "# List the contents of the directory - Make sure it does contain the files we want:\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/drive/My Drive/Colab Notebooks\n",
            "/content/drive/My Drive/Colab Notebooks\n",
            " 1.png\n",
            "' AI homework 1 - torch intro'\n",
            "'AI homework 2 - neural networks.ipynb'\n",
            "'AI homework PT 3 - generative conv models'\n",
            "'Copy of AI class - PyTorch - Tensors, grad, and logistic regression'\n",
            "'Copy of convert_to_html.ipynb'\n",
            "'Copy of MITx - Clinical Concept Extraction.ipynb'\n",
            "'cVAE AI homework PT 3 - generative conv models'\n",
            " homework_01.ipynb\n",
            " homework_02.ipynb\n",
            " homework_03.ipynb\n",
            "'Phys 2401 (1).ipynb'\n",
            "'Phys 2401.ipynb'\n",
            " Phys_2401.ipynb\n",
            " Project_1_Student_code.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVDJhqE1VXMA"
      },
      "source": [
        "+ Move to the section called **Loading the data**.\n",
        "\n",
        "### Instructions for personal computers\n",
        "\n",
        "#### If you have just downloaded the notebook and you are running it locally\n",
        "+ Locate the folder in which you have the notebook.\n",
        "+ Right click on the two files above and then \"Save As.\" Make sure that the selected format is \"text\" and that you save them in the same folder that contains this notebook.\n",
        "+ Move to the section called **Loading the data**.\n",
        "\n",
        "#### If you have cloned the entire github repository of the class to your local computer\n",
        "\n",
        "There is nothing to do. You already have the files in the same folder as this notebook.\n",
        "If the code below that loads the data does not work, then you are probably not running this notebook from the copy in the github repository.\n",
        "\n",
        "+ Move to the section called **Loading the data**.\n",
        "\n",
        "### Loading the data\n",
        "\n",
        "If you have done everything correctly up to this point you must have the files in the right directory and accessible from this notebook.\n",
        "Let's test this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wh8tdlM6VXMA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "8e919d6d-114c-4c8f-dec1-fe87f2dce290"
      },
      "source": [
        "# If this fails you have a problem with the first file\n",
        "data_p1B = np.loadtxt('hw_03_p1B_data.txt')\n",
        "print(data_p1B)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-e4bf291c14de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# If this fails you have a problem with the first file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata_p1B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hw_03_p1B_data.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_p1B\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows)\u001b[0m\n\u001b[1;32m    959\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    533\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    534\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s not found.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: hw_03_p1B_data.txt not found."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Obq96QpcVXMB"
      },
      "source": [
        "# If this fails you have a problem with the second file\n",
        "data_p2 = np.loadtxt('hw_03_p2_data.txt')\n",
        "print(data_p1B)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJZ7VsV0VXMB"
      },
      "source": [
        "## Problem 1\n",
        "### Part A\n",
        "Let $X$ be a continuous random variable with CDF:\n",
        "$$\n",
        "F(x) = p(X \\le x).\n",
        "$$\n",
        "Show that the random variable\n",
        "$$\n",
        "Z = F(X)\n",
        "$$\n",
        "    is distributed uniformly in $[0,1]$.\n",
        "    Hint: Show that:\n",
        "$$\n",
        "    F_Z(z) := p(Z \\le z) = z.\n",
        "$$\n",
        "**Proof:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGoYJnIfVXMB"
      },
      "source": [
        "\n",
        "<br><br>\n",
        "$$ F_Z(z) = p(Z \\le z) = p (F(X) \\le z) $$ <br>\n",
        "$$ = p(X \\le F^{-1}(z))  = F(F^{-1}(z)) = z$$\n",
        "Thus Z is uniformly distributed.\n",
        "<br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDkz5B3QVXMC"
      },
      "source": [
        "### Part B"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZYzbdzPVXMC"
      },
      "source": [
        "**Note (Before you attempt this part of the problem):** To do this problem your Jupyter notebook needs to be able to see this data file: [hw_03_p1B_data.txt](https://raw.githubusercontent.com/PredictiveScienceLab/data-analytics-se/master/homework/hw_03_p1B_data.txt).\n",
        "For this to happen the file must be in the same folder as the Jupyter notebook notebook.\n",
        "There are two cases:\n",
        "+ If you are using Google Colab:\n",
        "    - In this Jupyter notebook do \"File->Save A Copy in Drive\"\n",
        "    - Write click on [hw_03_p1B_data.txt](https://raw.githubusercontent.com/PredictiveScienceLab/data-analytics-se/master/homework/hw_03_p1B_data.txt) and click \"Save Link As.\" Make sure that you save the link as text and that you make a note where it is.\n",
        "    - Open your Google Drive in a separate tab. Go to the folder \"Colab Notebooks\" which was automatically created when you saved a copy of the notebook. Drag and drop the hw_03_p1B_data.txt file you just downloaded in that folder.\n",
        "+ If you are running the Jupyter notebook on your own computer:\n",
        "    - If you cloned the github repository, then the file will be there.\n",
        "    - If you downloaded the notebook manually, then download the file as per the instructions for Google Colab and put it in the same folder as the Jupyter notebook.\n",
        "\n",
        "The theorem you have just proved is very useful when you want to test if a set of observations $x_1,x_2,\\dots,x_N$ has been indeed independent realizations of a random variable $X$ with CDF $F(x)$.\n",
        "Part A proves that, if this hypothesis is valid, then the transformed dataset $z_1,z_2,\\dots,z_N$, where\n",
        "$$\n",
        "z_i = F(x_i),\n",
        "$$\n",
        "should be distributed uniformely in $[0,1]$.\n",
        "In other words, the empirical histrogram of $z_1,z_2,\\dots,z_N$ should be a flat line.\n",
        "Use this observation to find the distribution from which this dataset was sampled:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lj-OMzTVXMC"
      },
      "source": [
        "# If the following fails, please read the intructions above\n",
        "data = np.loadtxt('hw_03_p1B_data.txt')\n",
        "fig, ax = plt.subplots()\n",
        "ax.hist(data, density=True, alpha=0.5)\n",
        "ax.set_xlabel('$x$')\n",
        "ax.set_ylabel('Empirical PDF')\n",
        "ax.set_title('Histogram of data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-I3EbVqVXMC"
      },
      "source": [
        "The correct distribution is one of the following:\n",
        "\n",
        "1. Standard normal, $\\mathcal{N}(0,1)$;\n",
        "\n",
        "2. Normal with mean 2 and variance 2, $\\mathcal{N}(2,2)$; or\n",
        "\n",
        "3. Exponential with rate parameter $1$, $\\mathcal{E}(1)$; or\n",
        "\n",
        "4. Exponential with rate parameter $2$, $\\mathcal{E}(2)$; or\n",
        "\n",
        "5. Exponential with rate parameter $10$, $\\mathcal{E}(10)$; or\n",
        "\n",
        "6. Gamma distribution with parameters $\\alpha=2.$ and $\\beta=3.$.\n",
        "\n",
        "Systematically go over these distributions and try to determine which one generated the data.\n",
        "All the required CDF's and inverse CDF's are implemented in [scipy.stats](https://docs.scipy.org/doc/scipy/reference/stats.html).\n",
        "Check also [scipy.stats.rv_continuous](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rv_continuous.html#scipy.stats.rv_continuous).)\n",
        "Please pay special attention to the defintiion of the probability distributions of the various random variables and how you can control their parameters.\n",
        "As a hint, here is how you can test for $\\mathcal{N}(0,1)$:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouzdieOqVXMC"
      },
      "source": [
        "# Testing for N(0,1):\n",
        "transformed_data = st.norm(loc=0, scale=1).cdf(data) # cdf() gives the CDF of a random variable\n",
        "# If the data came from N(0,1), the histogram of the transformed_data should match that of a uniform:\n",
        "fig, ax = plt.subplots()\n",
        "ax.hist(transformed_data, density=True, alpha=0.5)\n",
        "ax.plot(np.linspace(0, 1,50), np.ones(50), lw=2, color='r') # This is the line that you should try to much.\n",
        "ax.set_xlabel('$z = F(x)$')\n",
        "ax.set_ylabel('Empirical PDF')\n",
        "ax.set_title('Testing the $\\mathcal{N}(0,1)$');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zD-UgQU4VXMC"
      },
      "source": [
        "## Problem 2\n",
        "\n",
        "**Note:** This problem also requires a data file. This file: [hw_03_p2_data.txt](https://raw.githubusercontent.com/PredictiveScienceLab/data-analytics-se/master/homework/hw_03_p2_data.txt). Please follow the same directions we gave in Part B of Problem 1 above.\n",
        "\n",
        "Consider the following data set $x_1,\\dots,x_N$:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdOGCBg_VXMD"
      },
      "source": [
        "# If the following fails, please look at the note above.\n",
        "data = np.loadtxt('hw_03_p2_data.txt')\n",
        "data = np.array(data)\n",
        "fig, ax = plt.subplots()\n",
        "ax.hist(data, alpha=0.5)\n",
        "ax.set_xlabel('$x$')\n",
        "ax.set_ylabel('Empirical PDF')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlrxMKCGVXMD"
      },
      "source": [
        "Your goal is to generate a procedure that samples from the same distribution as the observed data. \n",
        "This is a variation of the standard *density estimation* problem.\n",
        "In general, this is a very difficult problem and we will see various ways to solve it later on.\n",
        "In this problem, you will develop a simple method that relies on the empirical CDF of the observed data.\n",
        "Needless to say, this method works only for one dimensional cases in which you have a lot of observations.\n",
        "\n",
        "The [empirical CDF](https://en.wikipedia.org/wiki/Empirical_distribution_function) of our data set, $x_1,\\dots,x_N$ is defined to be:\n",
        "$$\n",
        "\\hat{F}_N(x) = \\frac{\\text{Number of observations}\\;\\le x}{N} = \\frac{1}{N}\\sum_{i=1}^N 1_{[x_i,+\\infty]}(x),\n",
        "$$\n",
        "where $1_A(x)$ is the [indicator function](https://en.wikipedia.org/wiki/Indicator_function) of the set $A$.\n",
        "Using the, so called, [strong law of large numbers](https://en.wikipedia.org/wiki/Law_of_large_numbers#Strong_law), we can show that $\\hat{F}_N(x)$ converges to the true CDF of the data as $N\\rightarrow+\\infty$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25nhfx4MVXMD"
      },
      "source": [
        "### Part A\n",
        "\n",
        "Complete the code that calculates the empirical CDF:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQWT05m2VXMD"
      },
      "source": [
        "def myECDF_base(x):\n",
        "    \"\"\"\n",
        "    Make this code work if ``x`` is a simple scalar.\n",
        "    \n",
        "    :param x:    The point at which you want to observe the PDF.\n",
        "    :returns:    The value of the empirical CDF at ``x``.\n",
        "    \"\"\"\n",
        "    N = data.shape[0]\n",
        "    # Write your code here (delete the next line and return the right value)\n",
        "    raise NotImplementedError('Implement me!')\n",
        "\n",
        "# Vectorize your function (i.e., make it work with 1D numpy arrays).\n",
        "# See this: https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.vectorize.html\n",
        "myECDF = np.vectorize(myECDF_base)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8po33-6-VXMD"
      },
      "source": [
        "# You can test your results by comparing the empirical CDF you can get with of scipy.stats\n",
        "# The two should match almost exactly\n",
        "hist_rv = st.rv_histogram(np.histogram(data, bins=1000))\n",
        "fig, ax = plt.subplots()\n",
        "# The range in which the x's takes values:\n",
        "x_min = data.min()\n",
        "x_max = data.max()\n",
        "xx = np.linspace(x_min, x_max, 100)\n",
        "ax.plot(xx, myECDF(xx), label='My empirical CDF')\n",
        "ax.plot(xx, hist_rv.cdf(xx), '--', label='Empirical CDF from scipy.stats')\n",
        "ax.set_xlabel('$x$')\n",
        "ax.set_ylabel('Empirical CDF')\n",
        "plt.legend(loc='best')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zy-sKDUVXMD"
      },
      "source": [
        "### Part B\n",
        "\n",
        "Now complete the code that computes the inverse of the empirical CDF $\\hat{F}^{-1}$.\n",
        "There are may ways of doing this.\n",
        "Let's do it in a way that will teach us something about the root finding toolbox of numpy (see [this](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.root_scalar.html#scipy.optimize.root_scalar)).\n",
        "Mathematically, we wish to find a function $F^{-1}$ such that\n",
        "$$\n",
        "F(F^{-1}(u))) = u,\n",
        "$$\n",
        "for any $u\\in[0,1]$ (the domain in which $F(x)$ takes values).\n",
        "It is obvious that $F^{-1}(u)$ is the solution to the *root finding* problem:\n",
        "$$\n",
        "F(x^*) = u.\n",
        "$$\n",
        "Since we know that $F$ is increasing, this problem must have a unique solution for any $u\\in[0,1]$.\n",
        "To find this solution, we can use [Brent's method](https://en.wikipedia.org/wiki/Brent%27s_method).\n",
        "Please note, that the problem that this code solves is of the form:\n",
        "$$\n",
        "g(x^*) = 0.\n",
        "$$\n",
        "So, you will have to reformulate the original problem as:\n",
        "$$\n",
        "F(x^*) - u = 0.\n",
        "$$\n",
        "Study the [numpy implementation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.brentq.html#scipy.optimize.brentq) of Brent's method and complete the following code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ld7MnysaVXME"
      },
      "source": [
        "from scipy import optimize    # Gives you access to optimize.brentq\n",
        "\n",
        "def myiECDF_base(u):\n",
        "    \"\"\"\n",
        "    Evaluates the inverse of the empirical CDF.\n",
        "    \n",
        "    :param u:   A scalar at which to evaluate the function.\n",
        "    :returns:    The value of the inverse of the empirical CDF at ``u``.\n",
        "    \"\"\"\n",
        "    # Write your code here\n",
        "    # You will have to define a functioin to pass to optimize.brentq\n",
        "    # You can define this function in here\n",
        "    # (delete the next line and return the right value)\n",
        "    raise NotImplementedError('Implement me!')\n",
        "\n",
        "# Vectorize your function (i.e., make it work with 1D numpy arrays).\n",
        "# See this: https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.vectorize.html\n",
        "myiECDF = np.vectorize(myiECDF_base)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "43Qf2KB4VXME"
      },
      "source": [
        "# You can test your results by comparing the inverse of the empirical CDF you can get with scipy.stats\n",
        "# The two should match almost exactly\n",
        "hist_rv = st.rv_histogram(np.histogram(data, bins=1000))\n",
        "fig, ax = plt.subplots()\n",
        "uu = np.linspace(1e-3, 1, 100)    # For convergence issues we cannot start at 0\n",
        "ax.plot(uu, myiECDF(uu), label='Inverse of my empirical CDF')\n",
        "ax.plot(uu, hist_rv.ppf(uu), '--', label='Inverse of empirical CDF from scipy.stats')\n",
        "ax.set_xlabel('$x$')\n",
        "ax.set_ylabel('Inverse of empirical CDF')\n",
        "plt.legend(loc='best')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1h88zB_VXME"
      },
      "source": [
        "### Part C\n",
        "\n",
        "Now use the *inverse transform sampling* method to generate samples from same distribution as the original data.\n",
        "That is, you can now generate uniform samples:\n",
        "$$\n",
        "u_i \\sim U([0,1]),\n",
        "$$\n",
        "and transform them as:\n",
        "$$\n",
        "\\hat{x}_i = {\\hat{F}}^{-1}(u_i).\n",
        "$$\n",
        "The $\\hat{x}_i$'s generated in this way should have the same distribution of the data you started with.\n",
        "Verify this by comparing the histrogram of $1,000$ $\\hat{x}_i$ samples with the original data of this problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0c8LRK2VXME"
      },
      "source": [
        "# Write your code here.\n",
        "# Feel free to copy paste code from above."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpfscCJLVXME"
      },
      "source": [
        "## Problem 3\n",
        "\n",
        "This is a classic uncertainty propagation problem that you will have to solve using Monte Carlo sampling.\n",
        "Consider the following stochastic harmonic oscillator:\n",
        "$$\n",
        "\\begin{array}{ccc}\n",
        "\\ddot{y} + 2 \\zeta \\omega(X) \\dot{y} + \\omega^2(X)y &=& 0,\\\\\n",
        "y(0) &=& y_0(X),\\\\\n",
        "\\dot{y}(0) &=& v_0(X),\n",
        "\\end{array}\n",
        "$$\n",
        "where:\n",
        "+ $X = (X_1, X_2, X_3)$,\n",
        "+ $X_i \\sim N(0, 1)$,\n",
        "+ $\\omega(X) = 2\\pi + X_1$, \n",
        "+ $\\zeta = 0.01$,\n",
        "+ $y_0(X) = 1+ 0.1 X_2$, and\n",
        "+ $v_0 = 0.1 X_3$.\n",
        "\n",
        "In words, this stochastic harmonic oscillator has an uncertain natural frequency and uncertain initial conditions.\n",
        "\n",
        "Our goal is to propagate uncertainty through this dynamical system, i.e., estimate the mean and variance of its solution.\n",
        "A solver for this dynamical system is given below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMnj-xuhVXME"
      },
      "source": [
        "class Solver(object):\n",
        "    def __init__(self, nt=100, T=5):\n",
        "        \"\"\"\n",
        "        This is the initializer of the class.\n",
        "        \n",
        "        Arguments:\n",
        "            nt - The number of timesteps.\n",
        "            T  - The final time.\n",
        "        \"\"\"\n",
        "        self.nt = nt\n",
        "        self.T = T\n",
        "        self.t = np.linspace(0, T, nt) # The timesteps on which we will get the solution\n",
        "        # The following are not essential, but they are convenient\n",
        "        self.num_input = 3             # The number of inputs the class accepts\n",
        "        self.num_output = nt           # The number of outputs the class returns\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        \"\"\"\n",
        "        This special class method emulates a function call.\n",
        "        \n",
        "        Arguments:\n",
        "            x - A 1D numpy array with 3 elements. This represents the stochastic input x = (x1, x2, x3).\n",
        "        \"\"\"\n",
        "        ##uncertain quantities \n",
        "        x1 = x[0]\n",
        "        x2 = x[1]\n",
        "        x3 = x[2]\n",
        "        \n",
        "        #ODE parameters \n",
        "        omega = 2*np.pi + x1 \n",
        "        y10 = 1 + 0.1*x2\n",
        "        y20 = 0.1*x3\n",
        "        y0 = np.array([y10, y20])   #initial conditions \n",
        "        \n",
        "        #coefficient matrix \n",
        "        zeta = 0.01\n",
        "        k = omega**2    ##spring constant\n",
        "        c = 2*zeta*omega   ##damping coeff. \n",
        "        C = np.array([[0, 1],[-k, -c]])\n",
        "        \n",
        "        #RHS of the ODE system\n",
        "        def rhs(y, t):\n",
        "            return np.dot(C, y)\n",
        "        \n",
        "        y = scipy.integrate.odeint(rhs, y0, self.t)\n",
        "        \n",
        "        return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJ5T12a2VXMF"
      },
      "source": [
        "Let's plot a few samples of the forward model to demonstrate how the solver works."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itV5jpS-VXMF"
      },
      "source": [
        "# 1. Create the solver object\n",
        "solver = Solver()\n",
        "fig1, ax1 = plt.subplots()\n",
        "ax1.set_xlabel('$t$ (Time)')\n",
        "ax1.set_ylabel('$y(t)$ (Position)')\n",
        "fig2, ax2 = plt.subplots()\n",
        "ax2.set_xlabel('$t$ (Time)')\n",
        "ax2.set_ylabel('$\\dot{y}(t)$ (Velocity)')\n",
        "for i in range(2):\n",
        "    # Sample the random inputs (they are just standard normal)\n",
        "    x = np.random.randn(solver.num_input) # solver.num_input is just 3\n",
        "    # Evaluate the solver response\n",
        "    y = solver(x) # This returns an (num timesteps) x (num states) array (100 x 2 here)\n",
        "    # Plot the sample\n",
        "    ax1.plot(solver.t, y[:, 0])\n",
        "    ax2.plot(solver.t, y[:, 1], label='Sample {0:d}'.format(i+1))\n",
        "plt.legend(loc=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1LpN49EVXMF"
      },
      "source": [
        "For your convenience, here is code that takes many samples of the solver at once:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3bSZwcPVXMF"
      },
      "source": [
        "def take_samples_from_solver(num_samples):\n",
        "    \"\"\"\n",
        "    Takes ``num_samples`` from the ODE solver.\n",
        "    \n",
        "    Returns them in an array of the form: ``num_samples x 100 x 2`` (100 timesteps, 2 states (position, velocity))\n",
        "    \"\"\"\n",
        "    samples = np.ndarray((num_samples, 100, 2))\n",
        "    for i in range(num_samples):\n",
        "        samples[i, :, :] = solver(np.random.randn(solver.num_input))\n",
        "    return samples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcILtMynVXMF"
      },
      "source": [
        "It works like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9CV-quxVXMF"
      },
      "source": [
        "samples = take_samples_from_solver(50)\n",
        "print(samples.shape)\n",
        "print(samples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yf6F4xBKVXMF"
      },
      "source": [
        "### Part A\n",
        "Take 100 samples of the solver output and plot the estimated mean position and velocity as a function of time along with a 95\\% epistemic uncertainty interval around it. \n",
        "This interval captures how sure you are about the mean response when using only 100 Monte Carlo samples.\n",
        "You need to use the central limit theorem to find it (see the lecture notes)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmRO4xu2VXMF"
      },
      "source": [
        "samples = take_samples_from_solver(100)\n",
        "# Sampled positions are: samples[:, :, 0]\n",
        "# Sampled velocities are: samples[:, :, 1]\n",
        "# Sampled position at the 10th timestep is: samples[:, 9, 0]\n",
        "# etc.\n",
        "\n",
        "# Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RctQQm8NVXMF"
      },
      "source": [
        "### Part B\n",
        "\n",
        "Plot the epistemic uncertainty about the mean position at $t=5$s as a function of the number of samples. \n",
        "\n",
        "**Solution**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rO9LqxEwVXMF"
      },
      "source": [
        "# Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Av144EkPVXMG"
      },
      "source": [
        "### Part C\n",
        "Repeat part A and B for the squared response.\n",
        "That is, do exactly the same thing as above, but consider $y^2(t)$ and $\\dot{y}^2(t)$ instead of $y(t)$ and $\\dot{y}(t)$.\n",
        "How many samples do you need to estimate the mean squared response at $t=5$s with negligible epistemic uncertainty?\n",
        "\n",
        "**Solution**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bnfs0bXgVXMG"
      },
      "source": [
        "# Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcO6QmFGVXMG"
      },
      "source": [
        "### Part D\n",
        "\n",
        "Now that you know how many samples you need to estimate the mean of the response and the square response, use the formula:\n",
        "$$\n",
        "\\mathbb{V}[y(t)] = \\mathbb{E}[y^2(t)] - \\left(\\mathbb{E}[y(t)]\\right)^2,\n",
        "$$\n",
        "and similarly for $\\dot{y}(t)$, to estimate the variance of the position and the velocity with negligible epistemic uncertainty.\n",
        "Plot both quantities as a function of time.\n",
        "\n",
        "**Solution**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZAOjVKOVXMG"
      },
      "source": [
        "# Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3bYIS_WVXMG"
      },
      "source": [
        "### Part E\n",
        "\n",
        "Put together the estimated mean and variance to plot a 95\\% predictive interval for the position and the velocity as functions of time.\n",
        "\n",
        "**Solution**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2aSANqrVXMG"
      },
      "source": [
        "# Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svTrwtEfVXMG"
      },
      "source": [
        "-End-"
      ]
    }
  ]
}
